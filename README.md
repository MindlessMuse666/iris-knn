# KNN-классификация датасэта Ирисов Фишера <a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="MIT-License image"></a>

## 1. Описание проекта

Данный проект выполнен в рамках дисциплины "МДК 13.01 Основы применения методов искусственного интеллекта в программировании".

**Практическое занятие №9**

**Тема:** Метод k ближайших соседей (KNN) - алгоритм ленивого обучения

В этом проекте реализован алгоритм KNN для классификации набора данных Iris (Ирисы Фишера). Этот набор данных широко используется в задачах машинного обучения для демонстрации алгоритмов классификации. Мы загрузили данные, обучили модель KNN, оценили её производительность и визуализировали результаты.

Целью работы было изучение и применение метода KNN для решения задачи классификации, а также анализ и визуализация результатов с использованием различных библиотек Python.

## 2. Скриншоты выполненного задания и конспекта лекции

### 2.1. Скриншоты выполненного задания

#### 2.1.1. Основной скрипт [main.py](src/main.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/89174305-aaab-473d-bd4b-8c58e7560234" alt="main.py">
</p>

#### 2.1.2. Скрипт загрузки данных [data_loader.py](src/data_loader.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/a89d2b4c-dd77-4714-bc1a-4e26bb27e1d1" alt="data_loader.py">
</p>

#### 2.1.3. Скрипт обучения и предсказания с использованием KNN [knn_model.py](src/knn_model.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/e05a9044-0f2e-40c7-8d05-fd3d261523a2" alt="knn_model.py">
</p>

#### 2.1.4. Скрипт расчета метрик оценки модели [metrics.py](src/metrics.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/5373d464-5d78-477d-9074-a493192fdaf8" alt="metrics.py">
</p>

#### 2.1.5. Скрипт визуализации результатов [knn_model.py](src/visualization.py)
<p align="center">
  <img src="https://github.com/user-attachments/assets/4907dc65-5d26-4526-ba34-764dafed76b2" alt="visualization.py">
</p>

### 2.2. Конспект лекции
<p align="center">
  <img src="report\lecture-notes\lecture-notes-1.jpg" alt="lecture-notes-1.jpg">
  <img src="report\lecture-notes\lecture-notes-2.jpg" alt="lecture-notes-2.jpg">
  <img src="report\lecture-notes\lecture-notes-3.jpg" alt="lecture-notes-3.jpg">
</p>

## 3. Методика и подходы

### 3.1. Методы
В данном проекте были использованы следующие методы:

* **Загрузка данных:** Использовалась функция load_iris из библиотеки scikit-learn для загрузки набора данных Iris.
* **Разделение данных:** Данные были разделены на обучающую и тестовую выборки с помощью функции train_test_split из scikit-learn.
* **Обучение модели:** Модель KNN была обучена на обучающей выборке с использованием метода fit.
* **Предсказание классов:** Классы для тестовой выборки были предсказаны с использованием метода predict.
* **Оценка результатов:** Производительность модели была оценена с использованием метрик accuracy, precision, recall и F1-score, а также с использованием кросс-валидации.
* **Визуализация результатов:** Результаты были визуализированы с использованием библиотек Matplotlib, Seaborn и Plotly.

### 3.2. Алгоритмы

* **KNN (k-Nearest Neighbors):** Алгоритм классификации, основанный на принципе близости. Класс нового экземпляра данных определяется на основе классов k ближайших соседей.
* **Алгоритмы** построения графиков и диаграмм из библиотек Matplotlib, Seaborn и Plotly.

### 3.3. Подходы

* **Объектно-ориентированное программирование (ООП):** Проект был разработан с использованием принципов ООП. Основные компоненты проекта (загрузка данных, обучение модели, оценка метрик, визуализация) реализованы в виде отдельных классов.
* **Принципы SOLID, KISS и DRY:** При разработке кода старались следовать принципам SOLID, KISS и DRY для обеспечения модульности, читаемости и переиспользуемости кода.

### 3.4. Допущения и ограничения

* Набор данных Iris считается относительно простым для классификации.
* Параметры модели KNN (количество соседей, алгоритм поиска) были выбраны без проведения тщательной оптимизации.
* Визуализация границ решений строится только для первых двух признаков.

### 3.5. Инструменты, библиотеки и технологии

* **Python:** Основной язык программирования.
* **Pandas:** Для работы с данными в формате DataFrame.
* **Scikit-learn:** Для загрузки данных, разделения на обучающую и тестовую выборки, обучения модели KNN и оценки её производительности.
* **Matplotlib:** Для построения базовых графиков и диаграмм.
* **Seaborn:** Для улучшения визуализации данных и создания более информативных графиков.
* **Plotly:** Для создания интерактивных графиков.

## 4. Результаты

### 4.1. Краткое описание данных

* **Источник данных:** scikit-learn (набор данных встроен в библиотеку).
* **Формат данных:** Массив NumPy.
* **Описание набора данных:** Набор данных Iris содержит информацию о 150 экземплярах ирисов, каждый из которых характеризуется четырьмя признаками: длина чашелистика, ширина чашелистика, длина лепестка и ширина лепестка. Каждый экземпляр относится к одному из трех классов: Iris setosa, Iris versicolor или Iris virginica.

### 4.2. Предварительная обработка данных

* Данные были разделены на признаки (X) и целевую переменную (y).
* Данные были разделены на обучающую и тестовую выборки с использованием функции `train_test_split` из scikit-learn.
* Масштабирование данных не производилось, так как алгоритм KNN не очень чувствителен к масштабу признаков.

### 4.3. Графики и диаграммы

#### 4.3.1. График предсказанных и истинных значений: отображает предсказанные классы и истинные классы для тестовой выборки
<p align="center">
  <img src="report\graphics\predictions_vs_actual.png" alt="predictions_vs_actual">
</p>

#### 4.3.2. Pairplot (Plotly): визуализирует взаимосвязи между всеми парами признаков
<p align="center">
  <img src="report\graphics\iris_dataset_pairplot.png" alt="pairplot">
</p>

#### 4.3.3. Границы решений KNN: визуализирует границы решений, построенные алгоритмом KNN.
<p align="center">
  <img src="report\graphics\decision_boundaries.png" alt="decision_boundaries">
</p>

## 5. Анализ результатов
Метрики, использованные для оценки результатов:

* **Accuracy (точность):** Доля правильно классифицированных экземпляров.
* **Precision (точность):** Доля правильно предсказанных положительных экземпляров среди всех экземпляров, которые были предсказаны как положительные.
* **Recall (полнота):** Доля правильно предсказанных положительных экземпляров среди всех фактических положительных экземпляров.
* **F1-score:** Среднее гармоническое между точностью и полнотой.
* **Кросс-валидация (accuracy):** Оценка точности модели на основе 10-кратной кросс-валидации.

Метрики оценки (на тестовой выборке):
* **accuracy:** `1.0`
* **precision:** `1.0`
* **recall:** `1.0`
* **f1\_score:** `1.0`

**Кросс-валидация (accuracy):** `0.9666666666666668 (+/- 0.04472135954999579)`
<p align="center">
  <img src="https://github.com/user-attachments/assets/297177ed-f8a4-44be-88f8-ce191f285517" alt="console_output">
</p>

## 6. Выводы

В результате выполнения проекта была успешно реализована классификация набора данных Iris с использованием алгоритма KNN.  Метрики, полученные на тестовой выборке, показывают идеальную точность, полноту и F1-меру, что может указывать на переобучение модели или слишком простую задачу. Однако, результаты кросс-валидации показывают более реалистичную оценку точности (около 96.7%) с некоторым разбросом (стандартное отклонение около 4.5%). Это подтверждает, что модель хорошо обобщается на новые данные, но не является идеально точной.

## 7. Обсуждение возможных улучшений

* Провести более тщательную оптимизацию параметров модели KNN (количество соседей, алгоритм поиска).
* Использовать другие алгоритмы классификации и сравнить их производительность с KNN.
* Применить методы регуляризации для борьбы с переобучением.
* Расширить набор данных, добавив новые признаки или экземпляры.
* Рассмотреть возможность использования более сложных методов оценки модели, таких как кривые обучения.

## 8. Заключение

В ходе выполнения данной практической работы были получены навыки применения метода KNN для решения задачи классификации, а также навыки анализа и визуализации результатов с использованием различных библиотек Python.

## 9. Лицензия

Этот проект распространяется под лицензией MIT - смотрите файл [LICENSE](LICENSE) для деталей.

## 10. Автор

Бедин Владислав ([MindlessMuse666](https://github.com/MindlessMuse666))

* GitHub: [MindlessMuse666](https://github.com/MindlessMuse666 "Владислав: https://github.com/MindlessMuse666")
* Telegram: [@mindless_muse](t.me/mindless_muse)
* Gmail: [mindlessmuse.666@gmail.com](mindlessmuse.666@gmail.com)
